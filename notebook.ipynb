{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Guided Lab of Contrast-Consistent Search (CCS)\n",
    "\n",
    "\n",
    "## The Basic Idea\n",
    "\n",
    "### The Problem\n",
    "\n",
    "Using contrastive statements pairs (e.g. \"Is 1 + 1 = 2. Yes.\" and \"Is 1 + 1 = 2. No.\") we know that only one of them is true. A language model might \"know\" which one is true, even if it \"tells\" us that it doesn't know, e.g. because we prompted the model to roleplay as someone dumb.\n",
    "\n",
    "That is there is a \"true\" ceiling of knowledge that a model has, and a \"false\" ceiling that might be limited by how we've prompted the model or whether the model is in some sense \"lying.\"\n",
    "\n",
    "Can we analyze the model in a domain-independent way (e.g. not using any facts about arithmetic in the case of 1 + 1 = 2), to get to this true ceiling of knowledge?\n",
    "\n",
    "### The Proposed Approach\n",
    "\n",
    "Use some sort of classifier run on the model's internal representation of those statements to figure out which statement the model \"really\" believes is true and which one it \"really\" believes is false. We don't have ground truth so we'll have to come up with some sort of other classifier.\n",
    "\n",
    "In theory we could do all sorts of different classification approaches (e.g. just simple unsupervised clustering). The main thing we have to do is make sure that we aren't accidentally classifying just based on whether the word \"Yes\" or \"No\" appears in the text.\n",
    "\n",
    "CCS tries to get rid of the effects of \"Yes\" and \"No\" by mean and variance-normalization.\n",
    "\n",
    "Then CCS trains a neural net based on the consistency and confidence loss function outlined in the paper as a domain-independent way of trying to classify by truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from enum import Enum\n",
    "from typing import Literal\n",
    "\n",
    "import numpy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.cluster import KMeans\n",
    "from torch import tensor, Tensor\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, \\\n",
    "    PreTrainedTokenizerBase, TensorType, PreTrainedModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries for setting up everything\n",
    "\n",
    "This is the code that is necessary to scaffold the CCS process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_from_model(\n",
    "        model: PreTrainedModel,\n",
    "        tokenizer: PreTrainedTokenizerBase,\n",
    "        prompt: str,\n",
    "        max_length: int,\n",
    ") -> str:\n",
    "    tokens = tokenizer(prompt, return_tensors=TensorType.PYTORCH).input_ids.to(model.device)\n",
    "    outputs = model.generate(tokens)\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "\n",
    "\n",
    "def get_hidden_state_of_last_layer_last_token(\n",
    "        model: PreTrainedModel,\n",
    "        tokenizer: PreTrainedTokenizerBase,\n",
    "        input_text: str\n",
    ") -> Tensor:\n",
    "    tokens = tokenizer(input_text + tokenizer.eos_token,\n",
    "                       return_tensors=TensorType.PYTORCH).input_ids.to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(tokens, output_hidden_states=True)\n",
    "\n",
    "    representation_across_all_tuples = output[\"hidden_states\"]\n",
    "    # Last layer\n",
    "    layer_to_retrieve = -1\n",
    "    # Last token\n",
    "    token_idx_to_retrieve = -1\n",
    "    representation = representation_across_all_tuples[layer_to_retrieve][0, token_idx_to_retrieve].detach()\n",
    "    return representation\n",
    "\n",
    "\n",
    "# Remember whatever we use has to be binary\n",
    "class Answer(Enum):\n",
    "    TRUE = 1\n",
    "    FALSE = 2\n",
    "\n",
    "\n",
    "def review_opinion_as_text(review_opinion: Answer) -> str:\n",
    "    match review_opinion:\n",
    "        case Answer.TRUE:\n",
    "            return \"Yes\"\n",
    "        case Answer.FALSE:\n",
    "            return \"No\"\n",
    "\n",
    "\n",
    "def int_label_to_answer(label: int) -> Answer:\n",
    "    match label:\n",
    "        case 0:\n",
    "            return Answer.FALSE\n",
    "        case 1:\n",
    "            return Answer.TRUE\n",
    "        case _:\n",
    "            raise Exception(\"Got an unexpected label!\")\n",
    "\n",
    "\n",
    "PROMPT_TEXT = \\\n",
    "    \"Give a one word answer of \\\"Yes\\\" or \\\"No\\\". Do the following reviews express a positive sentiment?\\n\" + \\\n",
    "    \"\\\"If you've played the game, you know how divine the music is! Every single song tells a story of the game in the most perfect way possible.\\\" Yes.\\n\" + \\\n",
    "    \"\\\"I guess you have to be a romance novel lover for this one, and not a very discerning one. All others beware! It is absolute drivel.\\\" No.\\n\" + \\\n",
    "    \"\\\"I feel I have to write to keep others from wasting their money. This book seems to have been written by a 7th grader with poor grammatical skills for her age! As another reviewer points out, there is a misspelling on the cover, and I believe there is at least one per chapter. For example, it was mentioned twice that she had a 'lean' on her house. I was so distracted by the poor writing and weak plot, that I decided to read with a pencil in hand to mark all of the horrible grammar and spelling. Please don't waste your money.\\\" No.\\n\"\n",
    "\n",
    "\n",
    "def create_prompt(text: str, label: Answer) -> str:\n",
    "    \"\"\"\n",
    "    Given a review example (\"text\") and corresponding label (0 for negative, or 1\n",
    "    for positive), returns a zero-shot prompt for that example (which includes\n",
    "    that label as the answer).\n",
    "\n",
    "    (This is just one example of a simple, manually created prompt.)\n",
    "    \"\"\"\n",
    "    return PROMPT_TEXT + \"\\\"\" + text.replace(\"\\\"\", \"'\") + \"\\\"\" + \" \" + review_opinion_as_text(label)\n",
    "\n",
    "\n",
    "def get_hidden_states_multiple(model: PreTrainedModel, tokenizer: PreTrainedTokenizerBase, data: Dataset, max_n: int):\n",
    "    # Make sure that the model is in evaluation mode, not training mode\n",
    "    model.eval()\n",
    "    negative_opinions = []\n",
    "    positive_opinions = []\n",
    "    ground_truth_labels = []\n",
    "    for idx_to_retrieve in range(max_n):\n",
    "        movie_review = data[idx_to_retrieve][\"content\"]\n",
    "        ground_truth: int = data[idx_to_retrieve][\"label\"]\n",
    "        ground_truth_labels.append(ground_truth)\n",
    "        positive_opinion = get_hidden_state_of_last_layer_last_token(\n",
    "            model,\n",
    "            tokenizer,\n",
    "            create_prompt(movie_review, Answer.TRUE),\n",
    "        )\n",
    "        negative_opinion = get_hidden_state_of_last_layer_last_token(\n",
    "            model,\n",
    "            tokenizer,\n",
    "            create_prompt(movie_review, Answer.FALSE),\n",
    "        )\n",
    "        positive_opinions.append(positive_opinion)\n",
    "        negative_opinions.append(negative_opinion)\n",
    "\n",
    "    return np.stack(negative_opinions), np.stack(positive_opinions), np.stack(ground_truth_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m num_of_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m----> 2\u001b[0m neg_hs, pos_hs, y \u001b[38;5;241m=\u001b[39m get_hidden_states_multiple(\u001b[43mmodel\u001b[49m, tokenizer, data, num_of_examples)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "num_of_examples = 100\n",
    "neg_hs, pos_hs, y = get_hidden_states_multiple(model, tokenizer, data, num_of_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's verify that the model's representations are good\n",
    "\n",
    "Before trying CCS, let's make sure there exists a direction that classifies examples as true vs false with high accuracy; if logistic regression accuracy is bad, there's no hope of CCS doing well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "# let's create a simple 50/50 train split (the data is already randomized)\n",
    "n = len(y)\n",
    "neg_hs_train, neg_hs_test = neg_hs[:n//2], neg_hs[n//2:]\n",
    "pos_hs_train, pos_hs_test = pos_hs[:n//2], pos_hs[n//2:]\n",
    "y_train, y_test = y[:n//2], y[n//2:]\n",
    "\n",
    "# for simplicity we can just take the difference between positive and negative hidden states\n",
    "# (concatenating also works fine)\n",
    "x_train = neg_hs_train - pos_hs_train\n",
    "x_test = neg_hs_test - pos_hs_test\n",
    "\n",
    "lr = LogisticRegression(class_weight=\"balanced\")\n",
    "lr.fit(x_train, y_train)\n",
    "print(\"Logistic regression accuracy: {}\".format(lr.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's try CCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPProbe(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d, 100)\n",
    "        self.linear2 = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.linear1(x))\n",
    "        o = self.linear2(h)\n",
    "        return torch.sigmoid(o)\n",
    "\n",
    "class CCS(object):\n",
    "    def __init__(self, x0, x1, nepochs=1000, ntries=10, lr=1e-3, batch_size=-1, \n",
    "                 verbose=False, device=\"cuda\", linear=True, weight_decay=0.01, var_normalize=False):\n",
    "        # data\n",
    "        self.var_normalize = var_normalize\n",
    "        self.x0 = self.normalize(x0)\n",
    "        self.x1 = self.normalize(x1)\n",
    "        self.d = self.x0.shape[-1]\n",
    "\n",
    "        # training\n",
    "        self.nepochs = nepochs\n",
    "        self.ntries = ntries\n",
    "        self.lr = lr\n",
    "        self.verbose = verbose\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "        # probe\n",
    "        self.linear = linear\n",
    "        self.initialize_probe()\n",
    "        self.best_probe = copy.deepcopy(self.probe)\n",
    "\n",
    "        \n",
    "    def initialize_probe(self):\n",
    "        if self.linear:\n",
    "            self.probe = nn.Sequential(nn.Linear(self.d, 1), nn.Sigmoid())\n",
    "        else:\n",
    "            self.probe = MLPProbe(self.d)\n",
    "        self.probe.to(self.device)    \n",
    "\n",
    "\n",
    "    def normalize(self, x):\n",
    "        \"\"\"\n",
    "        Mean-normalizes the data x (of shape (n, d))\n",
    "        If self.var_normalize, also divides by the standard deviation\n",
    "        \"\"\"\n",
    "        normalized_x = x - x.mean(axis=0, keepdims=True)\n",
    "        if self.var_normalize:\n",
    "            normalized_x /= normalized_x.std(axis=0, keepdims=True)\n",
    "\n",
    "        return normalized_x\n",
    "\n",
    "        \n",
    "    def get_tensor_data(self):\n",
    "        \"\"\"\n",
    "        Returns x0, x1 as appropriate tensors (rather than np arrays)\n",
    "        \"\"\"\n",
    "        x0 = torch.tensor(self.x0, dtype=torch.float, requires_grad=False, device=self.device)\n",
    "        x1 = torch.tensor(self.x1, dtype=torch.float, requires_grad=False, device=self.device)\n",
    "        return x0, x1\n",
    "    \n",
    "\n",
    "    def get_loss(self, p0, p1):\n",
    "        \"\"\"\n",
    "        Returns the CCS loss for two probabilities each of shape (n,1) or (n,)\n",
    "        \"\"\"\n",
    "        informative_loss = (torch.min(p0, p1)**2).mean(0)\n",
    "        consistent_loss = ((p0 - (1-p1))**2).mean(0)\n",
    "        return informative_loss + consistent_loss\n",
    "\n",
    "\n",
    "    def get_acc(self, x0_test, x1_test, y_test):\n",
    "        \"\"\"\n",
    "        Computes accuracy for the current parameters on the given test inputs\n",
    "        \"\"\"\n",
    "        x0 = torch.tensor(self.normalize(x0_test), dtype=torch.float, requires_grad=False, device=self.device)\n",
    "        x1 = torch.tensor(self.normalize(x1_test), dtype=torch.float, requires_grad=False, device=self.device)\n",
    "        with torch.no_grad():\n",
    "            p0, p1 = self.best_probe(x0), self.best_probe(x1)\n",
    "        avg_confidence = 0.5*(p0 + (1-p1))\n",
    "        predictions = (avg_confidence.detach().cpu().numpy() < 0.5).astype(int)[:, 0]\n",
    "        acc = (predictions == y_test).mean()\n",
    "        acc = max(acc, 1 - acc)\n",
    "\n",
    "        return acc\n",
    "    \n",
    "        \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Does a single training run of nepochs epochs\n",
    "        \"\"\"\n",
    "        x0, x1 = self.get_tensor_data()\n",
    "        permutation = torch.randperm(len(x0))\n",
    "        x0, x1 = x0[permutation], x1[permutation]\n",
    "        \n",
    "        # set up optimizer\n",
    "        optimizer = torch.optim.AdamW(self.probe.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        \n",
    "        batch_size = len(x0) if self.batch_size == -1 else self.batch_size\n",
    "        nbatches = len(x0) // batch_size\n",
    "\n",
    "        # Start training (full batch)\n",
    "        for epoch in range(self.nepochs):\n",
    "            for j in range(nbatches):\n",
    "                x0_batch = x0[j*batch_size:(j+1)*batch_size]\n",
    "                x1_batch = x1[j*batch_size:(j+1)*batch_size]\n",
    "            \n",
    "                # probe\n",
    "                p0, p1 = self.probe(x0_batch), self.probe(x1_batch)\n",
    "\n",
    "                # get the corresponding loss\n",
    "                loss = self.get_loss(p0, p1)\n",
    "\n",
    "                # update the parameters\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        return loss.detach().cpu().item()\n",
    "    \n",
    "    def repeated_train(self):\n",
    "        best_loss = np.inf\n",
    "        for train_num in range(self.ntries):\n",
    "            self.initialize_probe()\n",
    "            loss = self.train()\n",
    "            if loss < best_loss:\n",
    "                self.best_probe = copy.deepcopy(self.probe)\n",
    "                best_loss = loss\n",
    "\n",
    "        return best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCS accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Train CCS without any labels\n",
    "ccs = CCS(neg_hs_train, pos_hs_train)\n",
    "ccs.repeated_train()\n",
    "\n",
    "# Evaluate\n",
    "ccs_acc = ccs.get_acc(neg_hs_test, pos_hs_test, y_test)\n",
    "print(\"CCS accuracy: {}\".format(ccs_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b80286374679f2ad472c61c83fc267d31329b5dea8e2dcaccb727123767724c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
